# Capstone
Deep Learning Techniques for Music Generation

This is my final project for the Flatiron DS immersive. I decided to tackle music generation and really dig deep in my exploration of the possibilities. There is a panoply of model types and techniques that can be used to analyse and generate music. One certainty is that music generation is the goal rather than a classification problem. Therefore, for the purposes of building a model, generative rather than discriminative models will be investigated. Perhaps a problem for a later date would be to build a discriminative music genre classifier, however, I imagine this could be quite difficult and would require training the model on a massive corpus of music. 

## Introduction

During my exploration of the field I found many papers outlining different techniques for music generation. One particularly useful document was "Deep Leaning Techniques for Music Generation" (Briot et al., 2019), which outlines the various data structures for music encoding, then delves into various neural network architectures and examples of specific models. 

There have been myriad attempts at generating music, with varied success (in my opinion). Something pertinent to music is the subjectivity of the material. What does one consider 'good' music? This subjectivity adds complexity when evaluating a seemingly arbitrary sample. Music is very deliberate, therefore, I imagine a computer will struggle to create human-sounding pieces. Music tells a story and conveys emotion meaning that a computer inherently cannot understand those dimensions. It will be interesting to see where computer generated music will go when pre-mapped by humans. 


